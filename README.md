# ResNet_different_activations
Trying to understand the performance of various activation functions

ReLu

Mish

LeakyReLu

PReLU

Swish
